# 书生浦语大模型实战营第二期介绍

大家好，欢迎来到书生浦语大模型实战营，这是我们的第二期活动。在第一期中，许多同学参加了我们的课程学习，并取得了很好的成果。

## 书生浦语大模型全年度开源体系

大模型已经成为发展通用人工智能的重要途径。从本世纪初到2021年、2022年，大家的研究更多集中在专用模型上，即针对特定任务采用特定模型解决问题。例如，人工智能中有语音识别、图像分类、人脸识别、围棋比赛等任务，分别有对应的专用模型，如阿尔法fold用于预测蛋白质结构，GPT-3用于文本生成等。

然而，近两年来，学术界和工业应用越来越倾向于发展通用大模型，即一个模型能够应对多种任务和模态。例如，CHEGBT能够处理从文本到文本的各类任务，GPT-4能够解决多种跨模态任务。这种趋势下，通用大模型成为研究热点，被认为是通往通用人工智能的关键途径。

## 书生浦语大模型的开源历程

书生浦语大模型自去年6月份首次发布以来，一直保持快速迭代。7月份，千亿参数大模型全面升级，支持8K语境和26种语言。同时，我们推出了全免费商用的7B开源模型和全链条工具体系。8月份发布了书生万卷1.0多模态预训练语料库，后续发布了升级版对话模型和开源智能体框架，支持intern LM2的升级转换。我们发布了123B迁移参数模型，9月份发布了中等尺寸的开源模型，并升级了开源工具链。

今年1月17号，internLM22正式开源，相比第一代模型有了显著提升，能够解决更多真实问题和复杂场景。书生浦语2.0面向不同使用需求，提供了不同尺寸和类型的模型。我们提供了7B轻量级模型，适用于轻量级研究和应用；20B综合性能更强的重量级模型，适用于复杂场景。每个尺寸的模型都包括intimal base、Inte2和chat三个不同模型。internLM2 base是高质量、强可塑性的模型基座，在其基础上强化了多个能力方向，取得了优异的评测成绩和通用语言能力。internLM2模型推荐用于下游进一步微调。同时，我们还有INTEMMARCHAT模型，在base模型基础上经过优化，面向对话交互。internLM2chat模型具备良好的指令遵循、共情、聊天和调用工具能力。

我们将所有模型面向社区开源，用户可以根据实际场景和需求选用。internLm M2的初心是回归语言建模本质，通过高质量语料和新一代数据清洗过滤技术提升模型能力。我们通过高质量语料驱动的数据负极方式，从互联网和语料库中复习更多类似语料，并针对性补齐新数据，加强模型在世界知识、梳理代码等核心能力上的差异。

## 书生浦语2.0的主要亮点

书生浦语2.0具备超长上下文能力，支持200,000 token长度，实现大海捞针测试，综合能力全面提升。20B模型在重点评测上可比肩GPT-3.5。模型具备优秀的对话和创作体验，如指定遵循能力、结构化创作能力。在APAA1V评测上超过GPT-3.5和Gemini Pro，工具调用能力得到升级，支持复杂智能体搭建。模型强化了内生计算能力，不借助外部工具或计算器，具备准确计算能力。通过加入代码解释器，在JS8K和max数学评测集上达到GPT-4水平。

## 从模型到应用的流程分析

从模型到最终应用，需要经过模型选型、业务场景微调、智能体构建、模型评测、部署上线等多个步骤。每个环节都需要大量代码开发和工具选择。为了简化这一流程，我们开发了书生浦语全链条工具体系，覆盖数据、预训练、微调、部署、评测、应用等环节。

## 开源工具体系介绍

我们在数据方面有书生万卷开源数据集，预训练方面有INTETRAIN和INTEEVIL框架，微调方面有x ta框架，部署方面开源了i m deploy工具，评测方面开源了open compass司南评测体系，智能体应用方面开源了legend和agent lego框架和工具箱。

